{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23883d6e",
   "metadata": {},
   "source": [
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a830b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33259a29",
   "metadata": {},
   "source": [
    "Setting the hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d775d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=10\n",
    "n_layers=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0f6e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH=\"/home/user/Desktop/implementation/\"\n",
    "PREPROCESS=True\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a05806",
   "metadata": {},
   "source": [
    "loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3f1c3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dataset=keras.datasets.mnist\n",
    "(train_images,train_labels),(test_images,test_labels)=mnist_dataset.load_data()\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e33d85",
   "metadata": {},
   "source": [
    "normalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfc68909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images=train_images/255\n",
    "test_images=test_images/255\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d476f7",
   "metadata": {},
   "source": [
    "adding extra dimension for convolution channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdc96ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images=np.array(train_images[...,tf.newaxis],requires_grad=False)\n",
    "test_images=np.array(test_images[...,tf.newaxis],requires_grad=False)#requires_grad??\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd156e4f",
   "metadata": {},
   "source": [
    "initilaizing a default.qubit device simulating a system of 4 qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf55ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f51f82",
   "metadata": {},
   "source": [
    "Initialising random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39ccfdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.44829694, 4.49366732, 3.78727399, 3.42360201]], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))#1 x 4 returned as tensor\n",
    "rand_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e473d9",
   "metadata": {},
   "source": [
    "qnode consists of a quantum function and a device on which it executes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e5f5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(phi):\n",
    "    # Encoding of 4 classical input values\n",
    "    for j in range(4):\n",
    "        qml.RY(np.pi * phi[j], wires=j)#an embedding layer of local Ry rotations\n",
    "\n",
    "    # Random quantum circuit\n",
    "    RandomLayers(rand_params, wires=list(range(4)))#a random circuit of n_layers rand_params is the weight first argument of weight is the number of layers and the second argument of weights is the number of rotations\n",
    "\n",
    "    # Measurement producing 4 classical output values\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(4)]#measurement in the computational basis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac29984",
   "metadata": {},
   "source": [
    "drawing the circuit for illustration purposes with random parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22e1b075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY(3.14)──╭RandomLayers(M0)─┤  <Z>\n",
      "1: ──RY(6.28)──├RandomLayers(M0)─┤  <Z>\n",
      "2: ──RY(9.42)──├RandomLayers(M0)─┤  <Z>\n",
      "3: ──RY(12.57)─╰RandomLayers(M0)─┤  <Z>\n"
     ]
    }
   ],
   "source": [
    "drawer = qml.draw(circuit)\n",
    "print(drawer([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf2937",
   "metadata": {},
   "source": [
    "Convolution the input image with many applications of the same quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77f5de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quanv(image):\n",
    "    out = np.zeros((14, 14, 4))#initilaising output image with 4 different channels\n",
    "\n",
    "    # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
    "    for j in range(0, 28, 2):\n",
    "        for k in range(0, 28, 2):\n",
    "            # Process a squared 2x2 region of the image with a quantum circuit\n",
    "            q_results = circuit(\n",
    "                [\n",
    "                    image[j, k, 0],\n",
    "                    image[j, k + 1, 0],\n",
    "                    image[j + 1, k, 0],\n",
    "                    image[j + 1, k + 1, 0]\n",
    "                ]\n",
    "            )\n",
    "            # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
    "            for c in range(4):#the 4 expectation values are mapped into 4 different channels of a single output pixel\n",
    "                out[j // 2, k // 2, c] = q_results[c]\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac7687",
   "metadata": {},
   "source": [
    "preprocessing the train and test images as the quanvoluional layer isnt trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b592884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum pre-processing of train images:\n",
      "60000/60000        \n",
      "Quantum pre-processing of test images:\n",
      "(60000, 14, 14, 4) \n"
     ]
    }
   ],
   "source": [
    "if PREPROCESS == True:\n",
    "    q_train_images = []\n",
    "    print(\"Quantum pre-processing of train images:\")\n",
    "    for idx, img in enumerate(train_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, 60000), end=\"\\r\")\n",
    "        q_train_images.append(quanv(img))\n",
    "    q_train_images = np.asarray(q_train_images)\n",
    "\n",
    "    q_test_images = []\n",
    "    print(\"\\nQuantum pre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"{}/{}        \".format(idx + 1,10000 ), end=\"\\r\")\n",
    "        q_test_images.append(quanv(img))\n",
    "    q_test_images = np.asarray(q_test_images)\n",
    "\n",
    "    # Save pre-processed images\n",
    "    np.save(SAVE_PATH + \"q_train_images.npy\", q_train_images)\n",
    "    np.save(SAVE_PATH + \"q_test_images.npy\", q_test_images)\n",
    "\n",
    "    print(q_train_images.shape)\n",
    "\n",
    "# Load pre-processed images\n",
    "q_train_images = np.load(SAVE_PATH + \"q_train_images.npy\")\n",
    "q_test_images = np.load(SAVE_PATH + \"q_test_images.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45c969c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15000/15000 - 27s - loss: 0.1232 - accuracy: 0.9626 - 27s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "15000/15000 - 27s - loss: 0.0555 - accuracy: 0.9827 - 27s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "15000/15000 - 26s - loss: 0.0389 - accuracy: 0.9881 - 26s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "15000/15000 - 26s - loss: 0.0345 - accuracy: 0.9895 - 26s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "15000/15000 - 27s - loss: 0.0256 - accuracy: 0.9926 - 27s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "15000/15000 - 27s - loss: 0.0230 - accuracy: 0.9936 - 27s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "15000/15000 - 26s - loss: 0.0213 - accuracy: 0.9938 - 26s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "15000/15000 - 26s - loss: 0.0202 - accuracy: 0.9948 - 26s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "15000/15000 - 27s - loss: 0.0195 - accuracy: 0.9952 - 27s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "15000/15000 - 27s - loss: 0.0156 - accuracy: 0.9959 - 27s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "def MyModel():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(14,14,4)))#convolution layer\n",
    "    model.add(MaxPool2D(2,2))#pooling layer\n",
    "\n",
    "    model.add(Flatten())#flattening to form 1 D array\n",
    "    model.add(Dense(100,activation='relu'))# hidden layer\n",
    "    model.add(Dense(10,activation='softmax'))#output layer\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "q_model = MyModel()\n",
    "\n",
    "q_history = q_model.fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966f480",
   "metadata": {},
   "source": [
    "Evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7bb4b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.9857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10511688143014908, 0.9857000112533569]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.evaluate(q_test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e72f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
