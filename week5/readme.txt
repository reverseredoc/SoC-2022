Week 5
In this week, I studied the research paper about Quanvolutioal Neural
Networks and implemented them on Jupyter notebook. Quanvolutioal Neural
Networks power image recognition with quantum circuits. CNNs have become
widely popular for image recognition due to their ability to extract features
from data in a hierarchical manner. These features are extracted using various
transformational layers most importantly the convolutional layers. In QNN, a
new type of transformational layer Quantum Convolution or Quanvolutioal
layer is introduced which operate on input data by locally transforming the
data using a number of random quantum circuits. This algorithm requires small
quantum circuits with little to no error correction.
The benefit of quanvolutioal layers was evaluated by comparing three kinds of
models built on the famous MNIST dataset QNN, CNN and Random NN. I
implemented all of the three models and QNN clearly had an advantage over
CNN and Random NN.
